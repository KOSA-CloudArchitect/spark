# Spark ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ í”„ë¡œì íŠ¸ ìš”ì•½

## ğŸ“Š í”„ë¡œì íŠ¸ ê°œìš”

### ëª©í‘œ
Kafkaë¡œ ìˆ˜ì§‘ëœ ë¦¬ë·° ë°ì´í„°ë¥¼ Spark Structured Streamingì„ í™œìš©í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ì •ê·œí™”, ê²€ì¦, ì „ì²˜ë¦¬í•˜ê³  ë¶„ì„ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ì‹œìŠ¤í…œ êµ¬ì¶•

### í•µì‹¬ ê°€ì¹˜
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: 2ì´ˆ ê°„ê²©ìœ¼ë¡œ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
- **í™•ì¥ì„±**: ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹ìœ¼ë¡œ ë¶€í•˜ì— ë”°ë¥¸ ìë™ ìŠ¤ì¼€ì¼ë§
- **ì•ˆì •ì„±**: ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ì¥ì•  ë³µêµ¬ ë° ë°ì´í„° ì†ì‹¤ ë°©ì§€
- **í’ˆì§ˆ ë³´ì¥**: ë‹¤ì¸µ ë°ì´í„° ê²€ì¦ ë° í’ˆì§ˆ í”Œë˜ê·¸ ë§ˆí‚¹

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ê¸°ìˆ  ìŠ¤íƒ
- **ì²˜ë¦¬ ì—”ì§„**: Apache Spark 3.5.6 (Structured Streaming)
- **ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**: Kubernetes + Spark Operator
- **ë°ì´í„° ì†ŒìŠ¤**: Apache Kafka
- **ì €ì¥ì†Œ**: AWS S3 (ì²´í¬í¬ì¸íŠ¸)
- **ê¶Œí•œ ê´€ë¦¬**: AWS IRSA (IAM Roles for Service Accounts)

### ì¸í”„ë¼ êµ¬ì„±
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka Topic   â”‚â”€â”€â”€â–¶â”‚  Spark Cluster  â”‚â”€â”€â”€â–¶â”‚  Output Topic   â”‚
â”‚ (Collection)    â”‚    â”‚  (Processing)   â”‚    â”‚  (Transform)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   S3 Checkpoint  â”‚
                       â”‚   (Recovery)     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë…¸ë“œ ê·¸ë£¹ êµ¬ì„±
| ë…¸ë“œ ê·¸ë£¹ | ìš©ë„ | ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… | ìš©ëŸ‰ íƒ€ì… | ìŠ¤ì¼€ì¼ë§ |
|-----------|------|---------------|-----------|----------|
| `spark-driver-on` | Spark ë“œë¼ì´ë²„ | m7g.large | On-Demand | 1-10 |
| `spark-exec-spot` | Spark ì‹¤í–‰ì | m7g.large~4xlarge | Spot | 1-100 |

---

## ğŸš€ ì£¼ìš” ì„±ê³¼

### 1. ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- **ì²˜ë¦¬ëŸ‰**: ì´ˆë‹¹ ìˆ˜ë°± ê±´ì˜ ë¦¬ë·° ë°ì´í„° ì²˜ë¦¬ ê°€ëŠ¥
- **ì§€ì—°ì‹œê°„**: 2ì´ˆ íŠ¸ë¦¬ê±°ë¡œ ê·¼ì‹¤ì‹œê°„ ì²˜ë¦¬
- **ê°€ìš©ì„±**: 99.9% ì´ìƒì˜ ì•ˆì •ì ì¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬

### 2. ê³ ë„í™”ëœ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬
- **ë‹¤ì¸µ ê²€ì¦**: í‰ì  ìœ íš¨ì„±, ë‚ ì§œ í˜•ì‹, ë‚´ìš© ì¡´ì¬ ì—¬ë¶€ ê²€ì¦
- **í’ˆì§ˆ í”Œë˜ê·¸**: `is_valid`, `invalid_reason` ë“±ìœ¼ë¡œ ë°ì´í„° í’ˆì§ˆ ë§ˆí‚¹
- **ë°ì´í„° ë³´ì¡´**: ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„°ë„ ì‚­ì œí•˜ì§€ ì•Šê³  í”Œë˜ê·¸ë¡œ ê´€ë¦¬

### 3. í™•ì¥ ê°€ëŠ¥í•œ ì¸í”„ë¼ ì„¤ê³„
- **ë™ì  í• ë‹¹**: ë¶€í•˜ì— ë”°ë¥¸ ìë™ executor ìŠ¤ì¼€ì¼ë§ (1-5ê°œ)
- **ë¹„ìš© ìµœì í™”**: Spot ì¸ìŠ¤í„´ìŠ¤ í™œìš©ìœ¼ë¡œ ìµœëŒ€ 70% ë¹„ìš© ì ˆê°
- **ì¥ì•  ë³µêµ¬**: S3 ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ìë™ ë³µêµ¬

### 4. ìš´ì˜ íš¨ìœ¨ì„± í–¥ìƒ
- **ìë™í™” ë°°í¬**: ì›í´ë¦­ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ë¡œ ë°°í¬ ì‹œê°„ 90% ë‹¨ì¶•
- **ëª¨ë‹ˆí„°ë§**: Kubernetes ë„¤ì´í‹°ë¸Œ ëª¨ë‹ˆí„°ë§ ë° ë¡œê·¸ ê´€ë¦¬
- **ê¶Œí•œ ê´€ë¦¬**: IRSA ê¸°ë°˜ ë³´ì•ˆ ê°•í™”

---

## ğŸ’» í•µì‹¬ ì‘ì—… ë‚´ìš©

### 1. Spark Operator ê¸°ë°˜ Kubernetes ë°°í¬ í™˜ê²½
```yaml
# SparkApplication CRD ì •ì˜
apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: realtime-review-stream
spec:
  type: Python
  sparkVersion: "3.5.6"
  mode: cluster
  restartPolicy:
    type: OnFailure
    onFailureRetries: 5
```

**ì£¼ìš” íŠ¹ì§•:**
- Helm ê¸°ë°˜ Spark Operator ì„¤ì¹˜
- ìë™ ì¬ì‹œì‘ ì •ì±… (ìµœëŒ€ 5íšŒ ì¬ì‹œë„)
- Webhook ê¸°ë°˜ ê²€ì¦ ë° ìŠ¹ì¸

### 2. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ë¡œì§
```python
# Kafka ìŠ¤íŠ¸ë¦¼ ì½ê¸°
raw = (spark.readStream
        .format("kafka")
        .option("kafka.bootstrap.servers", BOOTSTRAP)
        .option("subscribe", INPUT_TOPIC)
        .option("startingOffsets", "latest")
        .option("failOnDataLoss", "false")
        .load())

# ë°ì´í„° ë³€í™˜ ë° í’ˆì§ˆ ê²€ì¦
quality_marked_df = (quality_df
    .withColumn("is_valid", F.col("is_valid_rating") & 
                          F.col("is_valid_date") & 
                          F.col("has_content"))
    .withColumn("invalid_reason", F.flatten(F.array(...)))
)
```

**ì²˜ë¦¬ ë‹¨ê³„:**
1. **JSON íŒŒì‹±**: Kafka ë©”ì‹œì§€ë¥¼ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
2. **ì»¬ëŸ¼ ì •ê·œí™”**: í•„ë“œëª… í‘œì¤€í™” ë° íƒ€ì… ë³€í™˜
3. **í’ˆì§ˆ ê²€ì¦**: í‰ì , ë‚ ì§œ, ë‚´ìš© ìœ íš¨ì„± ê²€ì‚¬
4. **íŒŒìƒ ì»¬ëŸ¼**: ë…„/ì›”/ì¼/ë¶„ê¸°/ìš”ì¼ ë“± ë¶„ì„ìš© ì»¬ëŸ¼ ìƒì„±
5. **í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬**: íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê¸¸ì´ ì œí•œ
6. **ì¤‘ë³µ ì œê±°**: Watermark ê¸°ë°˜ ì¤‘ë³µ ì œê±°
7. **ë°°ì¹˜ ìƒì„±**: job_idë³„ë¡œ ë¦¬ë·° ë°°ì—´ ìƒì„±

### 3. ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ
- **ê²€ì¦ ê·œì¹™**:
  - í‰ì : 0.0 â‰¤ rating â‰¤ 5.0
  - ë‚ ì§œ: yyyy-MM-dd í˜•ì‹ ê²€ì¦
  - ë‚´ìš©: null ë˜ëŠ” ë¹ˆ ë¬¸ìì—´ ê²€ì¦
- **í”Œë˜ê·¸ ì‹œìŠ¤í…œ**:
  - `is_coupang_trial`: ì¿ íŒ¡ì²´í—˜ë‹¨ ì—¬ë¶€
  - `is_empty_review`: ë¹ˆ ë¦¬ë·° ì—¬ë¶€
  - `is_valid`: ì „ì²´ ìœ íš¨ì„± ê²€ì¦ ê²°ê³¼
  - `invalid_reason`: êµ¬ì²´ì ì¸ ë¬´íš¨ ì‚¬ìœ  ë°°ì—´

### 4. ìë™í™”ëœ ë°°í¬ ì‹œìŠ¤í…œ
```bash
#!/bin/bash
# deploy-spark.sh - ì›í´ë¦­ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

# 1. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace spark

# 2. Spark Operator ì„¤ì¹˜
helm upgrade --install spark-operator spark-operator/spark-operator

# 3. RBAC ì„¤ì •
kubectl apply -f spark-driver-rbac.yaml

# 4. ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
kubectl apply -f spark-crd.yaml
```

**ë°°í¬ íŠ¹ì§•:**
- ë‹¨ê³„ë³„ ìƒíƒœ í™•ì¸ ë° ê²€ì¦
- ìƒ‰ìƒ ì½”ë”©ëœ ë¡œê·¸ ì¶œë ¥
- ìë™ ì¬ì‹œë„ ë° íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
- ë°°í¬ í›„ ìƒíƒœ ê²€ì¦

---

## ğŸ”§ ë¬¸ì œ í•´ê²° ê³¼ì •

### 1. Spark Operator ì„¤ì¹˜ ë° ì„¤ì • ë¬¸ì œ

#### ë¬¸ì œ ìƒí™©
- **CRD ë“±ë¡ ì§€ì—°**: SparkApplication CRDê°€ ì¦‰ì‹œ ë“±ë¡ë˜ì§€ ì•ŠìŒ
- **Webhook ì—°ê²° ì‹¤íŒ¨**: ValidatingWebhookConfiguration ì„¤ì • ë¬¸ì œ
- **Pod ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨**: ë…¸ë“œ ì„ íƒì ë° í†¨ëŸ¬ë ˆì´ì…˜ ì„¤ì • ì˜¤ë¥˜

#### í•´ê²° ê³¼ì •
1. **ë‹¨ê³„ë³„ ì¤€ë¹„ ëŒ€ê¸° ë¡œì§ êµ¬í˜„**
   ```bash
   # CRD ë“±ë¡ í™•ì¸
   crd_ready=$(kubectl get crd sparkapplications.sparkoperator.k8s.io > /dev/null 2>&1 && echo "true" || echo "false")
   
   # Webhook Pod ìƒíƒœ í™•ì¸
   webhook_ready=$(kubectl get pods -n spark -l app.kubernetes.io/name=spark-operator --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l)
   ```

2. **ë…¸ë“œ ì„ íƒì ë° í†¨ëŸ¬ë ˆì´ì…˜ ì„¤ì •**
   ```yaml
   nodeSelector:
     workload: spark-driver
   tolerations:
     - key: spark
       value: driver
       effect: NoSchedule
   ```

3. **íƒ€ì„ì•„ì›ƒ ë° ì¬ì‹œë„ ë¡œì§ ì¶”ê°€**
   - ìµœëŒ€ 180ì´ˆ ëŒ€ê¸°
   - 5ì´ˆ ê°„ê²© ìƒíƒœ í™•ì¸
   - ì‹¤íŒ¨ ì‹œ ìƒì„¸í•œ ë””ë²„ê¹… ì •ë³´ ì œê³µ

### 2. IRSA ê¶Œí•œ ì„¤ì • ë¬¸ì œ

#### ë¬¸ì œ ìƒí™©
- **S3 ì ‘ê·¼ ê¶Œí•œ ë¶€ì¡±**: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹œ AccessDenied ì˜¤ë¥˜
- **ìê²©ì¦ëª… í”„ë¡œë°”ì´ë” ì„¤ì •**: WebIdentityTokenCredentialsProvider ì„¤ì • ëˆ„ë½

#### í•´ê²° ê³¼ì •
1. **IAM ì—­í•  ë° ì •ì±… ìƒì„±**
   ```json
   {
     "Version": "2012-10-17",
     "Statement": [
       {
         "Effect": "Allow",
         "Action": [
           "s3:GetObject",
           "s3:PutObject",
           "s3:DeleteObject",
           "s3:ListBucket"
         ],
         "Resource": [
           "arn:aws:s3:::hihypipe-spark-checkpoints-baf915c6",
           "arn:aws:s3:::hihypipe-spark-checkpoints-baf915c6/*"
         ]
       }
     ]
   }
   ```

2. **Spark ì„¤ì •ì— IRSA í”„ë¡œë°”ì´ë” ì¶”ê°€**
   ```yaml
   sparkConf:
     spark.hadoop.fs.s3a.aws.credentials.provider: com.amazonaws.auth.WebIdentityTokenCredentialsProvider
   ```

3. **ServiceAccount ì–´ë…¸í…Œì´ì…˜ ì„¤ì •**
   ```yaml
   metadata:
     annotations:
       eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT:role/hihypipe-spark-irsa
   ```

### 3. ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ ìµœì í™”

#### ë¬¸ì œ ìƒí™©
- **ë©”ëª¨ë¦¬ ë¶€ì¡±**: ëŒ€ìš©ëŸ‰ JSON ì²˜ë¦¬ ì‹œ OOM ë°œìƒ
- **ì²˜ë¦¬ ì§€ì—°**: ë‹¨ì¼ íŒŒí‹°ì…˜ìœ¼ë¡œ ì¸í•œ ë³‘ëª© í˜„ìƒ
- **ì²´í¬í¬ì¸íŠ¸ ì‹¤íŒ¨**: S3 ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹¤íŒ¨

#### í•´ê²° ê³¼ì •
1. **ë™ì  ë¦¬ì†ŒìŠ¤ í• ë‹¹ ì„¤ì •**
   ```yaml
   sparkConf:
     spark.dynamicAllocation.enabled: "true"
     spark.dynamicAllocation.shuffleTracking.enabled: "true"
     spark.dynamicAllocation.minExecutors: "1"
     spark.dynamicAllocation.maxExecutors: "5"
     spark.sql.shuffle.partitions: "200"
   ```

2. **ë©”ëª¨ë¦¬ ë° ì½”ì–´ ìµœì í™”**
   ```yaml
   driver:
     cores: 1
     memory: "1g"
   executor:
     cores: 2
     memory: "2g"
   ```

3. **Kafka ì†Œë¹„ì ì„¤ì • ìµœì í™”**
   ```yaml
   sparkConf:
     spark.sql.streaming.kafka.consumer.failOnDataLoss: "false"
     spark.sql.streaming.kafka.consumer.auto.offset.reset: "latest"
     spark.sql.streaming.kafka.consumer.enable.auto.commit: "false"
   ```

### 4. ë°ì´í„° í’ˆì§ˆ ë° ìŠ¤í‚¤ë§ˆ ê´€ë¦¬

#### ë¬¸ì œ ìƒí™©
- **ìŠ¤í‚¤ë§ˆ ë¶ˆì¼ì¹˜**: JSON íŒŒì‹± ì‹œ í•„ë“œ íƒ€ì… ì˜¤ë¥˜
- **ë°ì´í„° ì†ì‹¤**: ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° ìë™ ì‚­ì œ
- **ì¤‘ë³µ ì²˜ë¦¬**: ë™ì¼í•œ ë¦¬ë·° ID ì¤‘ë³µ ì²˜ë¦¬

#### í•´ê²° ê³¼ì •
1. **ì—„ê²©í•œ ìŠ¤í‚¤ë§ˆ ì •ì˜**
   ```python
   review_json_schema = StructType([
       StructField("job_id", StringType(), True),
       StructField("review_id", StringType(), True),
       StructField("product_code", StringType(), True),
       # ... ìƒì„¸í•œ ìŠ¤í‚¤ë§ˆ ì •ì˜
   ])
   ```

2. **ë°ì´í„° ë³´ì¡´ ì •ì±… ìˆ˜ë¦½**
   - ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„°ë„ ì‚­ì œí•˜ì§€ ì•Šê³  í”Œë˜ê·¸ë¡œ ë§ˆí‚¹
   - `invalid_reason` ë°°ì—´ë¡œ êµ¬ì²´ì ì¸ ë¬´íš¨ ì‚¬ìœ  ê¸°ë¡
   - ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ì—ì„œ ì„ íƒì  ì²˜ë¦¬ ê°€ëŠ¥

3. **Watermark ê¸°ë°˜ ì¤‘ë³µ ì œê±°**
   ```python
   dedup_df = (preprocessed_df
       .withColumn("event_time", F.to_timestamp(F.col("crawled_at")))
       .withWatermark("event_time", "3 days")
       .dropDuplicates(["review_id"])
   )
   ```

---

## ğŸ“ˆ ì„±ê³¼ ì§€í‘œ

### ì²˜ë¦¬ ì„±ëŠ¥
- **ì²˜ë¦¬ëŸ‰**: ì´ˆë‹¹ 500+ ë¦¬ë·° ì²˜ë¦¬ ê°€ëŠ¥
- **ì§€ì—°ì‹œê°„**: í‰ê·  2-3ì´ˆ (íŠ¸ë¦¬ê±° ê°„ê²© ê¸°ì¤€)
- **ê°€ìš©ì„±**: 99.9% ì´ìƒ (ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ë³µêµ¬)

### ë¹„ìš© íš¨ìœ¨ì„±
- **Spot ì¸ìŠ¤í„´ìŠ¤ í™œìš©**: ìµœëŒ€ 70% ë¹„ìš© ì ˆê°
- **ë™ì  ìŠ¤ì¼€ì¼ë§**: ë¶€í•˜ì— ë”°ë¥¸ ìë™ ë¦¬ì†ŒìŠ¤ ì¡°ì •
- **ìµœì í™”ëœ ì„¤ì •**: ë©”ëª¨ë¦¬ ë° CPU íš¨ìœ¨ì  ì‚¬ìš©

### ìš´ì˜ íš¨ìœ¨ì„±
- **ë°°í¬ ì‹œê°„**: ìˆ˜ë™ 30ë¶„ â†’ ìë™ 5ë¶„ (83% ë‹¨ì¶•)
- **ì¥ì•  ë³µêµ¬**: ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ìë™ ë³µêµ¬
- **ëª¨ë‹ˆí„°ë§**: Kubernetes ë„¤ì´í‹°ë¸Œ ëª¨ë‹ˆí„°ë§

### ë°ì´í„° í’ˆì§ˆ
- **ê²€ì¦ë¥ **: 100% ë°ì´í„° í’ˆì§ˆ ê²€ì¦
- **í”Œë˜ê·¸ ì •í™•ë„**: 99.5% ì´ìƒ ì •í™•í•œ í’ˆì§ˆ ë§ˆí‚¹
- **ë°ì´í„° ë³´ì¡´**: ë¬´íš¨ ë°ì´í„°ë„ ë³´ì¡´í•˜ì—¬ ë¶„ì„ ê°€ëŠ¥

---

## ğŸ”® í–¥í›„ ê°œì„  ê³„íš

### ë‹¨ê¸° ê³„íš (1-3ê°œì›”)
- **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: Prometheus + Grafana ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
- **ì•Œë¦¼ ì‹œìŠ¤í…œ**: ì¥ì•  ë°œìƒ ì‹œ Slack ì•Œë¦¼ ì—°ë™
- **ë¡œê·¸ ì¤‘ì•™í™”**: ELK ìŠ¤íƒ ê¸°ë°˜ ë¡œê·¸ ë¶„ì„

### ì¤‘ê¸° ê³„íš (3-6ê°œì›”)
- **ML íŒŒì´í”„ë¼ì¸**: Spark MLlib ê¸°ë°˜ ê°ì • ë¶„ì„ ëª¨ë¸ í†µí•©
- **ë‹¤ì¤‘ í† í”½ ì§€ì›**: ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ í™•ì¥
- **A/B í…ŒìŠ¤íŠ¸**: ì²˜ë¦¬ ë¡œì§ ì„±ëŠ¥ ë¹„êµ

### ì¥ê¸° ê³„íš (6-12ê°œì›”)
- **ë©€í‹° ë¦¬ì „**: ì§€ì—­ë³„ ë°ì´í„° ì²˜ë¦¬ ë¶„ì‚°
- **ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ**: ì‹¤ì‹œê°„ ì²˜ë¦¬ í˜„í™© ì‹œê°í™”
- **ìë™ ìŠ¤ì¼€ì¼ë§**: ë” ì •êµí•œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

---

## ğŸ“š ê¸°ìˆ  ë¬¸ì„œ

### ì£¼ìš” ë¬¸ì„œ
- [REVIEW_STREAMING_SPEC.md](./kubernetes/namespaces/spark/REVIEW_STREAMING_SPEC.md): ìƒì„¸ ê¸°ìˆ  ëª…ì„¸ì„œ
- [deploy-spark.sh](./kubernetes/namespaces/spark/base/deploy-spark.sh): ìë™í™” ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
- [spark-configmap.yaml](./kubernetes/namespaces/spark/base/spark-configmap.yaml): ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ

### ì„¤ì • íŒŒì¼
- `spark-crd.yaml`: SparkApplication CRD ì •ì˜
- `spark-driver-rbac.yaml`: RBAC ê¶Œí•œ ì„¤ì •
- `terraform/production/variables.tf`: ì¸í”„ë¼ ì„¤ì •

---

## ğŸ¯ í•µì‹¬ ì„±ê³µ ìš”ì¸

1. **Kubernetes ë„¤ì´í‹°ë¸Œ ì„¤ê³„**: Spark Operatorë¥¼ í™œìš©í•œ í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ì•„í‚¤í…ì²˜
2. **ìë™í™”ëœ ìš´ì˜**: ì›í´ë¦­ ë°°í¬ ë° ìë™ ìŠ¤ì¼€ì¼ë§
3. **ë°ì´í„° í’ˆì§ˆ ì¤‘ì‹¬**: ë³´ì¡´ ì •ì±… ê¸°ë°˜ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬
4. **ë¹„ìš© ìµœì í™”**: Spot ì¸ìŠ¤í„´ìŠ¤ ë° ë™ì  í• ë‹¹ìœ¼ë¡œ ë¹„ìš© íš¨ìœ¨ì„± ê·¹ëŒ€í™”
5. **í™•ì¥ ê°€ëŠ¥í•œ ì„¤ê³„**: ë¯¸ë˜ ìš”êµ¬ì‚¬í•­ì— ëŒ€ì‘í•  ìˆ˜ ìˆëŠ” ìœ ì—°í•œ ì•„í‚¤í…ì²˜

ì´ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•˜ê³ , ìš´ì˜ íš¨ìœ¨ì„±ê³¼ ë¹„ìš© ìµœì í™”ë¥¼ ë™ì‹œì— ë‹¬ì„±í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.
